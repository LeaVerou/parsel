{"version":3,"file":"parsel.min.js","sources":["../../parsel.ts"],"sourcesContent":["export const enum TokenType {\n  Class = 'class',\n  Attribute = 'attribute',\n  Id = 'id',\n  Type = 'type',\n  Universal = 'universal',\n  PseudoElement = 'pseudo-element',\n  PseudoClass = 'pseudo-class',\n  Comma = 'comma',\n  Combinator = 'combinator'\n}\n\nexport interface Tokens {\n  type: string;\n  content: string;\n  name: string;\n  namespace?: string;\n  value?: string;\n  pos: [number, number];\n  operator?: string;\n  argument?: string;\n  subtree?: AST;\n  caseSensitive?: 'i';\n}\n\nexport interface Complex {\n  type: 'complex';\n  combinator: string;\n  right: AST;\n  left: AST;\n}\n\nexport interface Compound {\n  type: 'compound';\n  list: Tokens[];\n}\n\nexport interface List {\n  type: 'list';\n  list: AST[];\n}\n\nexport type AST = Complex | Compound | List | Tokens;\n\nexport const TOKENS: Record<string, RegExp> = {\n  [TokenType.Attribute]:\n    /\\[\\s*(?:(?<namespace>\\*|[-\\w]*)\\|)?(?<name>[-\\w\\u{0080}-\\u{FFFF}]+)\\s*(?:(?<operator>\\W?=)\\s*(?<value>.+?)\\s*(\\s(?<caseSensitive>[iIsS]))?\\s*)?\\]/gu,\n  [TokenType.Id]: /#(?<name>(?:\\\\.|[-\\w\\u{0080}-\\u{FFFF}])+)/gu,\n  [TokenType.Class]: /\\.(?<name>(?:\\\\.|[-\\w\\u{0080}-\\u{FFFF}])+)/gu,\n  [TokenType.Comma]: /\\s*,\\s*/g, // must be before combinator\n  [TokenType.Combinator]: /\\s*[\\s>+~]\\s*/g, // this must be after attribute\n  [TokenType.PseudoElement]:\n    /::(?<name>[-\\w\\u{0080}-\\u{FFFF}]+)(?:\\((?<argument>¶+)\\))?/gu, // this must be before pseudo-class\n  [TokenType.PseudoClass]:\n    /:(?<name>[-\\w\\u{0080}-\\u{FFFF}]+)(?:\\((?<argument>¶+)\\))?/gu,\n  [TokenType.Universal]: /(?:(?<namespace>\\*|[-\\w]*)\\|)?\\*/gu,\n  [TokenType.Type]:\n    /(?:(?<namespace>\\*|[-\\w]*)\\|)?(?<name>[-\\w\\u{0080}-\\u{FFFF}]+)|\\*/gu // this must be last\n};\n\nexport const TOKENS_WITH_PARENS = new Set<string>([\n  TokenType.PseudoClass,\n  TokenType.PseudoElement\n]);\nexport const TOKENS_WITH_STRINGS = new Set<string>([\n  ...TOKENS_WITH_PARENS,\n  TokenType.Attribute\n]);\nexport const TOKENS_TO_TRIM = new Set<string>([\n  TokenType.Combinator,\n  TokenType.Comma\n]);\n\nexport const RECURSIVE_PSEUDO_CLASSES = new Set<string>([\n  'not',\n  'is',\n  'where',\n  'has',\n  'matches',\n  '-moz-any',\n  '-webkit-any',\n  'nth-child',\n  'nth-last-child'\n]);\n\nconst nthChildRegExp = /(?<index>[\\dn+-]+)\\s+of\\s+(?<subtree>.+)/;\nexport const RECURSIVE_PSEUDO_CLASSES_ARGS: Record<string, RegExp> = {\n  'nth-child': nthChildRegExp,\n  'nth-last-child': nthChildRegExp\n};\n\nconst TOKENS_FOR_RESTORE = { ...TOKENS };\nfor (const pseudoType of [\n  TokenType.PseudoElement,\n  TokenType.PseudoClass\n] as const) {\n  TOKENS_FOR_RESTORE[pseudoType] = RegExp(\n    TOKENS[pseudoType].source.replace('(?<argument>¶+)', '(?<argument>.+)'),\n    'gu'\n  );\n}\n\nfunction scanParentheses(text: string, offset: number): string {\n  let nesting = 0;\n  let result = '';\n  for (; offset < text.length; offset++) {\n    const char = text[offset];\n    switch (char) {\n      case '(':\n        ++nesting;\n        break;\n      case ')':\n        --nesting;\n        break;\n    }\n    result += char;\n    if (nesting === 0) {\n      return result;\n    }\n  }\n  throw new Error(`Mismatched parenthesis starting at offset ${offset}`);\n}\n\nexport function tokenizeBy(text: string, grammar = TOKENS): Tokens[] {\n  if (!text) {\n    return [];\n  }\n\n  const tokens: (Tokens | string)[] = [text];\n  for (const type in grammar) {\n    const pattern = grammar[type];\n    for (let i = 0; i < tokens.length; i++) {\n      const token = tokens[i];\n      if (typeof token !== 'string') {\n        continue;\n      }\n\n      pattern.lastIndex = 0;\n      const match = pattern.exec(token);\n      if (!match) {\n        continue;\n      }\n\n      const from = match.index - 1;\n      const args: (Tokens | string)[] = [];\n      const content = match[0];\n\n      const before = token.slice(0, from + 1);\n      if (before) {\n        args.push(before);\n      }\n\n      args.push({\n        ...(match.groups as unknown as Tokens),\n        type,\n        content\n      });\n\n      const after = token.slice(from + content.length + 1);\n      if (after) {\n        args.push(after);\n      }\n\n      tokens.splice(i, 1, ...args);\n    }\n  }\n\n  let offset = 0;\n  for (const token of tokens) {\n    switch (typeof token) {\n      case 'string':\n        throw new Error(\n          `Unexpected sequence ${token} found at index ${offset}`\n        );\n      case 'object':\n        offset += token.content.length;\n        token.pos = [offset - token.content.length, offset];\n        if (TOKENS_TO_TRIM.has(token.type)) {\n          token.content = token.content.trim() || ' ';\n        }\n        break;\n    }\n  }\n\n  return tokens as Tokens[];\n}\n\nconst STRING_PATTERN = /(['\"])((?:\\\\.|\\\\\\n|[^\\\\\\n])+?)\\1/g;\nexport function tokenize(selector: string, grammar = TOKENS) {\n  type TokenString = { value: string; offset: number };\n\n  if (!selector) {\n    return null;\n  }\n\n  // Prevent leading/trailing whitespace be interpreted as combinators\n  selector = selector.trim();\n\n  // Replace strings with whitespace strings (to preserve offsets)\n  const stringExpressions: TokenString[] = [];\n  selector = selector.replace(\n    STRING_PATTERN,\n    (value: string, quote: string, content: string, offset: number) => {\n      stringExpressions.push({ value, offset });\n      return `${quote}${'§'.repeat(content.length)}${quote}`;\n    }\n  );\n\n  // Now that strings are out of the way, extract parens and replace them with parens with whitespace (to preserve offsets)\n  const parenthesisExpressions: TokenString[] = [];\n  {\n    let pos = 0;\n    let offset: number;\n    while ((offset = selector.indexOf('(', pos)) > -1) {\n      const value = scanParentheses(selector, offset);\n      parenthesisExpressions.push({ value, offset });\n      selector = `${selector.substring(0, offset)}(${'¶'.repeat(\n        value.length - 2\n      )})${selector.substring(offset + value.length)}`;\n      pos = offset + value.length;\n    }\n  }\n\n  // Now we have no nested structures and we can parse with regexes\n  const tokens = tokenizeBy(selector, grammar);\n\n  // Now restore parens and strings in reverse order\n  function restoreNested(\n    strings: TokenString[],\n    regex: RegExp,\n    types: Set<string>\n  ) {\n    for (const str of strings) {\n      for (const token of tokens) {\n        if (\n          !types.has(token.type) ||\n          token.pos[0] >= str.offset ||\n          str.offset >= token.pos[1]\n        ) {\n          continue;\n        }\n        const content = token.content;\n        token.content = token.content.replace(regex, str.value);\n        if (token.content !== content) {\n          // actually changed?\n          // Re-evaluate groups\n          TOKENS_FOR_RESTORE[token.type].lastIndex = 0;\n          const match = TOKENS_FOR_RESTORE[token.type].exec(token.content);\n          Object.assign(token, match!.groups);\n        }\n      }\n    }\n  }\n\n  restoreNested(parenthesisExpressions, /\\(¶+\\)/, TOKENS_WITH_PARENS);\n  restoreNested(stringExpressions, /(['\"])§+?\\1/, TOKENS_WITH_STRINGS);\n\n  return tokens;\n}\n\n/**\n *  Convert a flat list of tokens into a tree of complex & compound selectors\n */\nfunction nestTokens(tokens: Tokens[], { list = true } = {}): AST {\n  if (list && tokens.find((t: { type: string }) => t.type === 'comma')) {\n    const selectors: AST[] = [];\n    const temp = [];\n\n    for (let i = 0; i < tokens.length; i++) {\n      if (tokens[i].type === 'comma') {\n        if (temp.length === 0) {\n          throw new Error('Incorrect comma at ' + i);\n        }\n\n        selectors.push(nestTokens(temp, { list: false }));\n        temp.length = 0;\n      } else {\n        temp.push(tokens[i]);\n      }\n    }\n\n    if (temp.length === 0) {\n      throw new Error('Trailing comma');\n    } else {\n      selectors.push(nestTokens(temp, { list: false }));\n    }\n\n    return { type: 'list', list: selectors };\n  }\n\n  for (let i = tokens.length - 1; i >= 0; i--) {\n    let token = tokens[i];\n\n    if (token.type === 'combinator') {\n      let left = tokens.slice(0, i);\n      let right = tokens.slice(i + 1);\n\n      return {\n        type: 'complex',\n        combinator: token.content,\n        left: nestTokens(left),\n        right: nestTokens(right)\n      };\n    }\n  }\n\n  switch (tokens.length) {\n    case 0:\n      throw new Error('Could not build AST.');\n    case 1:\n      // If we're here, there are no combinators, so it's just a list.\n      return tokens[0];\n    default:\n      return {\n        type: 'compound',\n        list: [...tokens] // clone to avoid pointers messing up the AST\n      };\n  }\n}\n\n/**\n * Traverse an AST (or part thereof), in depth-first order\n */\nexport function walk(\n  node: AST | undefined,\n  visit: (node: AST, parentNode?: AST) => void,\n  /**\n   * @internal\n   */\n  parent?: AST\n) {\n  if (!node) {\n    return;\n  }\n\n  if ('left' in node && 'right' in node) {\n    walk(node.left, visit, node);\n    walk(node.right, visit, node);\n  } else if ('list' in node) {\n    for (let n of node.list) {\n      walk(n, visit, node);\n    }\n  }\n\n  visit(node, parent);\n}\n\nexport interface ParserOptions {\n  recursive?: boolean;\n  list?: boolean;\n}\n\n/**\n * Parse a CSS selector\n *\n * @param selector - The selector to parse\n * @param options.recursive - Whether to parse the arguments of pseudo-classes like :is(), :has() etc. Defaults to true.\n * @param options.list - Whether this can be a selector list (A, B, C etc). Defaults to true.\n */\nexport function parse(\n  selector: string,\n  { recursive = true, list = true }: ParserOptions = {}\n): AST | undefined {\n  const tokens = tokenize(selector);\n  if (!tokens) {\n    return;\n  }\n\n  const ast = nestTokens(tokens, { list });\n\n  if (!recursive) {\n    return ast;\n  }\n\n  walk(ast, (node) => {\n    if (node.type === TokenType.PseudoClass && node.argument) {\n      if (RECURSIVE_PSEUDO_CLASSES.has(node.name)) {\n        let argument = node.argument;\n        const childArg = RECURSIVE_PSEUDO_CLASSES_ARGS[node.name];\n        if (childArg) {\n          const match = childArg.exec(argument);\n          if (!match) {\n            return;\n          }\n\n          Object.assign(node, match.groups);\n          argument = match.groups!['subtree'];\n        }\n        if (argument) {\n          Object.assign(node, {\n            subtree: parse(argument, { recursive: true, list: true })\n          });\n        }\n      }\n    }\n  });\n\n  return ast;\n}\n\n/**\n * To convert the specificity array to a number\n */\nexport function specificityToNumber(\n  specificity: number[],\n  base: number\n): number {\n  base = base || Math.max(...specificity) + 1;\n  return specificity[0] * (base << 1) + specificity[1] * base + specificity[2];\n}\n\n/**\n * Calculate specificity of a selector.\n *\n * If the selector is a list, the max specificity is returned.\n */\nexport function specificity(selector: string | AST): number[] {\n  let ast: string | AST | undefined = selector;\n  if (typeof ast === 'string') {\n    ast = parse(ast, { recursive: true });\n  }\n  if (!ast) {\n    return [];\n  }\n\n  if (ast.type === 'list' && 'list' in ast) {\n    let base = 10;\n    const specificities = ast.list.map((ast) => {\n      const sp = specificity(ast);\n      base = Math.max(base, ...specificity(ast));\n      return sp;\n    });\n    const numbers = specificities.map((ast) => specificityToNumber(ast, base));\n    return specificities[numbers.indexOf(Math.max(...numbers))];\n  }\n\n  let ret = [0, 0, 0];\n  walk(ast, (node) => {\n    if (node.type === 'id') {\n      ret[0]++;\n    } else if (node.type === 'class' || node.type === 'attribute') {\n      ret[1]++;\n    } else if (\n      (node.type === 'type' && node.content !== '*') ||\n      node.type === 'pseudo-element'\n    ) {\n      ret[2]++;\n    } else if (node.type === 'pseudo-class' && node.name !== 'where') {\n      if (RECURSIVE_PSEUDO_CLASSES.has(node.name) && node.subtree) {\n        const sub = specificity(node.subtree);\n        sub.forEach((s, i) => (ret[i] += s));\n        // :nth-child() & :nth-last-child() add (0, 1, 0) to the specificity of their most complex selector\n        if (node.name === 'nth-child' || node.name === 'nth-last-child') {\n          ret[1]++;\n        }\n      } else {\n        ret[1]++;\n      }\n    }\n  });\n\n  return ret;\n}\n"],"names":["TokenType","TOKENS","Attribute","Id","Class","Comma","Combinator","PseudoElement","PseudoClass","Universal","Type","TOKENS_WITH_PARENS","Set","TOKENS_WITH_STRINGS","TOKENS_TO_TRIM","RECURSIVE_PSEUDO_CLASSES","nthChildRegExp","RECURSIVE_PSEUDO_CLASSES_ARGS","TOKENS_FOR_RESTORE","pseudoType","RegExp","source","replace","scanParentheses","text","offset","nesting","result","length","char","Error","tokenizeBy","grammar","tokens","type","pattern","i","token","lastIndex","match","exec","from","index","args","content","before","slice","push","groups","after","splice","pos","has","trim","STRING_PATTERN","tokenize","selector","stringExpressions","value","quote","repeat","parenthesisExpressions","indexOf","substring","restoreNested","strings","regex","types","str","Object","assign","nestTokens","list","find","t","selectors","temp","left","right","combinator","walk","node","visit","parent","n","parse","recursive","ast","argument","name","childArg","subtree","specificityToNumber","specificity","base","Math","max","specificities","map","sp","numbers","ret","forEach","s"],"mappings":"IAAkBA,GAAlB,SAAkBA,GAChBA,gBACAA,wBACAA,UACAA,cACAA,wBACAA,iCACAA,6BACAA,gBACAA,yBACD,CAVD,CAAkBA,IAAAA,aA4CLC,EAAiC,CAC5C,CAACD,EAAUE,WACT,sJACF,CAACF,EAAUG,IAAK,8CAChB,CAACH,EAAUI,OAAQ,+CACnB,CAACJ,EAAUK,OAAQ,WACnB,CAACL,EAAUM,YAAa,iBACxB,CAACN,EAAUO,eACT,+DACF,CAACP,EAAUQ,aACT,8DACF,CAACR,EAAUS,WAAY,qCACvB,CAACT,EAAUU,MACT,uEAGSC,EAAqB,IAAIC,IAAY,CAChDZ,EAAUQ,YACVR,EAAUO,gBAECM,EAAsB,IAAID,IAAY,IAC9CD,EACHX,EAAUE,YAECY,EAAiB,IAAIF,IAAY,CAC5CZ,EAAUM,WACVN,EAAUK,QAGCU,EAA2B,IAAIH,IAAY,CACtD,MACA,KACA,QACA,MACA,UACA,WACA,cACA,YACA,mBAGII,EAAiB,2CACVC,EAAwD,CACnE,YAAaD,EACb,iBAAkBA,GAGdE,EAAqB,IAAKjB,GAChC,IAAK,MAAMkB,IAAc,CACvBnB,EAAUO,cACVP,EAAUQ,aAEVU,EAAmBC,GAAcC,OAC/BnB,EAAOkB,GAAYE,OAAOC,QAAQ,kBAAmB,mBACrD,MAIJ,SAASC,EAAgBC,EAAcC,GACrC,IAAIC,EAAU,EACVC,EAAS,GACb,KAAOF,EAASD,EAAKI,OAAQH,IAAU,CACrC,MAAMI,EAAOL,EAAKC,GAClB,OAAQI,GACN,IAAK,MACDH,EACF,MACF,IAAK,MACDA,EAIN,GADAC,GAAUE,EACM,IAAZH,EACF,OAAOC,EAGX,MAAM,IAAIG,MAAM,6CAA6CL,IAC/D,UAEgBM,EAAWP,EAAcQ,EAAU/B,GACjD,IAAKuB,EACH,MAAO,GAGT,MAAMS,EAA8B,CAACT,GACrC,IAAK,MAAMU,KAAQF,EAAS,CAC1B,MAAMG,EAAUH,EAAQE,GACxB,IAAK,IAAIE,EAAI,EAAGA,EAAIH,EAAOL,OAAQQ,IAAK,CACtC,MAAMC,EAAQJ,EAAOG,GACrB,GAAqB,iBAAVC,EACT,SAGFF,EAAQG,UAAY,EACpB,MAAMC,EAAQJ,EAAQK,KAAKH,GAC3B,IAAKE,EACH,SAGF,MAAME,EAAOF,EAAMG,MAAQ,EACrBC,EAA4B,GAC5BC,EAAUL,EAAM,GAEhBM,EAASR,EAAMS,MAAM,EAAGL,EAAO,GACjCI,GACFF,EAAKI,KAAKF,GAGZF,EAAKI,KAAK,IACJR,EAAMS,OACVd,OACAU,YAGF,MAAMK,EAAQZ,EAAMS,MAAML,EAAOG,EAAQhB,OAAS,GAC9CqB,GACFN,EAAKI,KAAKE,GAGZhB,EAAOiB,OAAOd,EAAG,KAAMO,IAI3B,IAAIlB,EAAS,EACb,IAAK,MAAMY,KAASJ,EAClB,cAAeI,GACb,IAAK,SACH,MAAM,IAAIP,MACR,uBAAuBO,oBAAwBZ,KAEnD,IAAK,SACHA,GAAUY,EAAMO,QAAQhB,OACxBS,EAAMc,IAAM,CAAC1B,EAASY,EAAMO,QAAQhB,OAAQH,GACxCX,EAAesC,IAAIf,EAAMH,QAC3BG,EAAMO,QAAUP,EAAMO,QAAQS,QAAU,KAMhD,OAAOpB,CACT,CAEA,MAAMqB,EAAiB,6CACPC,EAASC,EAAkBxB,EAAU/B,GAGnD,IAAKuD,EACH,OAAO,KAITA,EAAWA,EAASH,OAGpB,MAAMI,EAAmC,GACzCD,EAAWA,EAASlC,QAClBgC,GACA,CAACI,EAAeC,EAAef,EAAiBnB,KAC9CgC,EAAkBV,KAAK,CAAEW,QAAOjC,WACzB,GAAGkC,IAAQ,IAAIC,OAAOhB,EAAQhB,UAAU+B,OAKnD,MAAME,EAAwC,GAC9C,CACE,IACIpC,EADA0B,EAAM,EAEV,MAAQ1B,EAAS+B,EAASM,QAAQ,IAAKX,KAAS,GAAG,CACjD,MAAMO,EAAQnC,EAAgBiC,EAAU/B,GACxCoC,EAAuBd,KAAK,CAAEW,QAAOjC,WACrC+B,EAAW,GAAGA,EAASO,UAAU,EAAGtC,MAAW,IAAImC,OACjDF,EAAM9B,OAAS,MACZ4B,EAASO,UAAUtC,EAASiC,EAAM9B,UACvCuB,EAAM1B,EAASiC,EAAM9B,QAKzB,MAAMK,EAASF,EAAWyB,EAAUxB,GAGpC,SAASgC,EACPC,EACAC,EACAC,GAEA,IAAK,MAAMC,KAAOH,EAChB,IAAK,MAAM5B,KAASJ,EAAQ,CAC1B,IACGkC,EAAMf,IAAIf,EAAMH,OACjBG,EAAMc,IAAI,IAAMiB,EAAI3C,QACpB2C,EAAI3C,QAAUY,EAAMc,IAAI,GAExB,SAEF,MAAMP,EAAUP,EAAMO,QAEtB,GADAP,EAAMO,QAAUP,EAAMO,QAAQtB,QAAQ4C,EAAOE,EAAIV,OAC7CrB,EAAMO,UAAYA,EAAS,CAG7B1B,EAAmBmB,EAAMH,MAAMI,UAAY,EAC3C,MAAMC,EAAQrB,EAAmBmB,EAAMH,MAAMM,KAAKH,EAAMO,SACxDyB,OAAOC,OAAOjC,EAAOE,EAAOS,UASpC,OAHAgB,EAAcH,EAAwB,SAAUlD,GAChDqD,EAAcP,EAAmB,cAAe5C,GAEzCoB,CACT,CAKA,SAASsC,EAAWtC,GAAkBuC,KAAEA,GAAO,GAAS,IACtD,GAAIA,GAAQvC,EAAOwC,MAAMC,GAAmC,UAAXA,EAAExC,OAAmB,CACpE,MAAMyC,EAAmB,GACnBC,EAAO,GAEb,IAAK,IAAIxC,EAAI,EAAGA,EAAIH,EAAOL,OAAQQ,IACjC,GAAuB,UAAnBH,EAAOG,GAAGF,KAAkB,CAC9B,GAAoB,IAAhB0C,EAAKhD,OACP,MAAM,IAAIE,MAAM,sBAAwBM,GAG1CuC,EAAU5B,KAAKwB,EAAWK,EAAM,CAAEJ,MAAM,KACxCI,EAAKhD,OAAS,OAEdgD,EAAK7B,KAAKd,EAAOG,IAIrB,GAAoB,IAAhBwC,EAAKhD,OACP,MAAM,IAAIE,MAAM,kBAKlB,OAHE6C,EAAU5B,KAAKwB,EAAWK,EAAM,CAAEJ,MAAM,KAGnC,CAAEtC,KAAM,OAAQsC,KAAMG,GAG/B,IAAK,IAAIvC,EAAIH,EAAOL,OAAS,EAAGQ,GAAK,EAAGA,IAAK,CAC3C,IAAIC,EAAQJ,EAAOG,GAEnB,GAAmB,eAAfC,EAAMH,KAAuB,CAC/B,IAAI2C,EAAO5C,EAAOa,MAAM,EAAGV,GACvB0C,EAAQ7C,EAAOa,MAAMV,EAAI,GAE7B,MAAO,CACLF,KAAM,UACN6C,WAAY1C,EAAMO,QAClBiC,KAAMN,EAAWM,GACjBC,MAAOP,EAAWO,KAKxB,OAAQ7C,EAAOL,QACb,KAAK,EACH,MAAM,IAAIE,MAAM,wBAClB,KAAK,EAEH,OAAOG,EAAO,GAChB,QACE,MAAO,CACLC,KAAM,WACNsC,KAAM,IAAIvC,IAGlB,UAKgB+C,EACdC,EACAC,EAIAC,GAEA,GAAKF,EAAL,CAIA,GAAI,SAAUA,GAAQ,UAAWA,EAC/BD,EAAKC,EAAKJ,KAAMK,EAAOD,GACvBD,EAAKC,EAAKH,MAAOI,EAAOD,QACnB,GAAI,SAAUA,EACnB,IAAK,IAAIG,KAAKH,EAAKT,KACjBQ,EAAKI,EAAGF,EAAOD,GAInBC,EAAMD,EAAME,GACd,UAcgBE,EACd7B,GACA8B,UAAEA,GAAY,EAAId,KAAEA,GAAO,GAAwB,IAEnD,MAAMvC,EAASsB,EAASC,GACxB,IAAKvB,EACH,OAGF,MAAMsD,EAAMhB,EAAWtC,EAAQ,CAAEuC,SAEjC,OAAKc,GAILN,EAAKO,GAAMN,IACT,GAAIA,EAAK/C,OAASlC,EAAUQ,aAAeyE,EAAKO,UAC1CzE,EAAyBqC,IAAI6B,EAAKQ,MAAO,CAC3C,IAAID,EAAWP,EAAKO,SACpB,MAAME,EAAWzE,EAA8BgE,EAAKQ,MACpD,GAAIC,EAAU,CACZ,MAAMnD,EAAQmD,EAASlD,KAAKgD,GAC5B,IAAKjD,EACH,OAGF8B,OAAOC,OAAOW,EAAM1C,EAAMS,QAC1BwC,EAAWjD,EAAMS,OAAiB,QAEhCwC,GACFnB,OAAOC,OAAOW,EAAM,CAClBU,QAASN,EAAMG,EAAU,CAAEF,WAAW,EAAMd,MAAM,UAOrDe,GA1BEA,CA2BX,UAKgBK,EACdC,EACAC,GAGA,OADAA,EAAOA,GAAQC,KAAKC,OAAOH,GAAe,EACnCA,EAAY,IAAMC,GAAQ,GAAKD,EAAY,GAAKC,EAAOD,EAAY,EAC5E,UAOgBA,EAAYrC,GAC1B,IAAI+B,EAAgC/B,EAIpC,GAHmB,iBAAR+B,IACTA,EAAMF,EAAME,EAAK,CAAED,WAAW,MAE3BC,EACH,MAAO,GAGT,GAAiB,SAAbA,EAAIrD,MAAmB,SAAUqD,EAAK,CACxC,IAAIO,EAAO,GACX,MAAMG,EAAgBV,EAAIf,KAAK0B,KAAKX,IAClC,MAAMY,EAAKN,EAAYN,GAEvB,OADAO,EAAOC,KAAKC,IAAIF,KAASD,EAAYN,IAC9BY,CAAE,IAELC,EAAUH,EAAcC,KAAKX,GAAQK,EAAoBL,EAAKO,KACpE,OAAOG,EAAcG,EAAQtC,QAAQiC,KAAKC,OAAOI,KAGnD,IAAIC,EAAM,CAAC,EAAG,EAAG,GAyBjB,OAxBArB,EAAKO,GAAMN,IACT,GAAkB,OAAdA,EAAK/C,KACPmE,EAAI,UACC,GAAkB,UAAdpB,EAAK/C,MAAkC,cAAd+C,EAAK/C,KACvCmE,EAAI,UACC,GACU,SAAdpB,EAAK/C,MAAoC,MAAjB+C,EAAKrC,SAChB,mBAAdqC,EAAK/C,KAELmE,EAAI,UACC,GAAkB,iBAAdpB,EAAK/C,MAAyC,UAAd+C,EAAKQ,KAC9C,GAAI1E,EAAyBqC,IAAI6B,EAAKQ,OAASR,EAAKU,QAAS,CAC/CE,EAAYZ,EAAKU,SACzBW,SAAQ,CAACC,EAAGnE,IAAOiE,EAAIjE,IAAMmE,IAEf,cAAdtB,EAAKQ,MAAsC,mBAAdR,EAAKQ,MACpCY,EAAI,UAGNA,EAAI,QAKHA,CACT"}